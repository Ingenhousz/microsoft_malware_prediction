import sys
sys.path.append("/sfs/qumulo/qhome/yx3fz/.local/lib/python3.6/site-packages")

import logging
import pandas as pd
import numpy as np
import lightgbm as lgb
from tqdm import tqdm
import random

from scipy.sparse import vstack, csr_matrix, save_npz, load_npz
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import StratifiedKFold
import gc
gc.enable()

from contextlib import contextmanager
import time

logger = logging.getLogger(__name__)
logging.basicConfig(
    format='[%(levelname)s] %(asctime)s %(filename)s: %(lineno)d: %(message)s',
    datefmt='%Y-%m-%d:%H:%M:%S',
    level=logging.DEBUG)


@contextmanager
def timer(title):
    t0 = time.time()
    yield
    logger.info("{} - done in {:.0f}s".format(title, time.time() - t0))


def sample_train(s=10000):

    dtypes = {
        'MachineIdentifier': 'category',
        'ProductName': 'category',
        'EngineVersion': 'category',
        'AppVersion': 'category',
        'AvSigVersion': 'category',
        'IsBeta': 'int8',
        'RtpStateBitfield': 'float16',
        'IsSxsPassiveMode': 'int8',
        'DefaultBrowsersIdentifier': 'float16',
        'AVProductStatesIdentifier': 'float32',
        'AVProductsInstalled': 'float16',
        'AVProductsEnabled': 'float16',
        'HasTpm': 'int8',
        'CountryIdentifier': 'int16',
        'CityIdentifier': 'float32',
        'OrganizationIdentifier': 'float16',
        'GeoNameIdentifier': 'float16',
        'LocaleEnglishNameIdentifier': 'int8',
        'Platform': 'category',
        'Processor': 'category',
        'OsVer': 'category',
        'OsBuild': 'int16',
        'OsSuite': 'int16',
        'OsPlatformSubRelease': 'category',
        'OsBuildLab': 'category',
        'SkuEdition': 'category',
        'IsProtected': 'float16',
        'AutoSampleOptIn': 'int8',
        'PuaMode': 'category',
        'SMode': 'float16',
        'IeVerIdentifier': 'float16',
        'SmartScreen': 'category',
        'Firewall': 'float16',
        'UacLuaenable': 'float32',
        'Census_MDC2FormFactor': 'category',
        'Census_DeviceFamily': 'category',
        'Census_OEMNameIdentifier': 'float16',
        'Census_OEMModelIdentifier': 'float32',
        'Census_ProcessorCoreCount': 'float16',
        'Census_ProcessorManufacturerIdentifier': 'float16',
        'Census_ProcessorModelIdentifier': 'float16',
        'Census_ProcessorClass': 'category',
        'Census_PrimaryDiskTotalCapacity': 'float32',
        'Census_PrimaryDiskTypeName': 'category',
        'Census_SystemVolumeTotalCapacity': 'float32',
        'Census_HasOpticalDiskDrive': 'int8',
        'Census_TotalPhysicalRAM': 'float32',
        'Census_ChassisTypeName': 'category',
        'Census_InternalPrimaryDiagonalDisplaySizeInInches': 'float16',
        'Census_InternalPrimaryDisplayResolutionHorizontal': 'float16',
        'Census_InternalPrimaryDisplayResolutionVertical': 'float16',
        'Census_PowerPlatformRoleName': 'category',
        'Census_InternalBatteryType': 'category',
        'Census_InternalBatteryNumberOfCharges': 'float32',
        'Census_OSVersion': 'category',
        'Census_OSArchitecture': 'category',
        'Census_OSBranch': 'category',
        'Census_OSBuildNumber': 'int16',
        'Census_OSBuildRevision': 'int32',
        'Census_OSEdition': 'category',
        'Census_OSSkuName': 'category',
        'Census_OSInstallTypeName': 'category',
        'Census_OSInstallLanguageIdentifier': 'float16',
        'Census_OSUILocaleIdentifier': 'int16',
        'Census_OSWUAutoUpdateOptionsName': 'category',
        'Census_IsPortableOperatingSystem': 'int8',
        'Census_GenuineStateName': 'category',
        'Census_ActivationChannel': 'category',
        'Census_IsFlightingInternal': 'float16',
        'Census_IsFlightsDisabled': 'float16',
        'Census_FlightRing': 'category',
        'Census_ThresholdOptIn': 'float16',
        'Census_FirmwareManufacturerIdentifier': 'float16',
        'Census_FirmwareVersionIdentifier': 'float32',
        'Census_IsSecureBootEnabled': 'int8',
        'Census_IsWIMBootEnabled': 'float16',
        'Census_IsVirtualDevice': 'float16',
        'Census_IsTouchEnabled': 'int8',
        'Census_IsPenCapable': 'int8',
        'Census_IsAlwaysOnAlwaysConnectedCapable': 'float16',
        'Wdft_IsGamer': 'float16',
        'Wdft_RegionIdentifier': 'float16',
        'HasDetections': 'int8'
    }

    filename = 'input/train.csv'
    n = sum(1 for line in open(filename)) - 1  # number of records in file (excludes header)
    skip = sorted(random.sample(range(1, n + 1), n - s))  # the 0-indexed header will not be included in the skip list
    train = pd.read_csv(filename, skiprows=skip, low_memory=True)

    return train

def read_files(debug=True):
    num_row = 10000 if debug else None
    dtypes = {
        'MachineIdentifier': 'category',
        'ProductName': 'category',
        'EngineVersion': 'category',
        'AppVersion': 'category',
        'AvSigVersion': 'category',
        'IsBeta': 'int8',
        'RtpStateBitfield': 'float16',
        'IsSxsPassiveMode': 'int8',
        'DefaultBrowsersIdentifier': 'float16',
        'AVProductStatesIdentifier': 'float32',
        'AVProductsInstalled': 'float16',
        'AVProductsEnabled': 'float16',
        'HasTpm': 'int8',
        'CountryIdentifier': 'int16',
        'CityIdentifier': 'float32',
        'OrganizationIdentifier': 'float16',
        'GeoNameIdentifier': 'float16',
        'LocaleEnglishNameIdentifier': 'int8',
        'Platform': 'category',
        'Processor': 'category',
        'OsVer': 'category',
        'OsBuild': 'int16',
        'OsSuite': 'int16',
        'OsPlatformSubRelease': 'category',
        'OsBuildLab': 'category',
        'SkuEdition': 'category',
        'IsProtected': 'float16',
        'AutoSampleOptIn': 'int8',
        'PuaMode': 'category',
        'SMode': 'float16',
        'IeVerIdentifier': 'float16',
        'SmartScreen': 'category',
        'Firewall': 'float16',
        'UacLuaenable': 'float32',
        'Census_MDC2FormFactor': 'category',
        'Census_DeviceFamily': 'category',
        'Census_OEMNameIdentifier': 'float16',
        'Census_OEMModelIdentifier': 'float32',
        'Census_ProcessorCoreCount': 'float16',
        'Census_ProcessorManufacturerIdentifier': 'float16',
        'Census_ProcessorModelIdentifier': 'float16',
        'Census_ProcessorClass': 'category',
        'Census_PrimaryDiskTotalCapacity': 'float32',
        'Census_PrimaryDiskTypeName': 'category',
        'Census_SystemVolumeTotalCapacity': 'float32',
        'Census_HasOpticalDiskDrive': 'int8',
        'Census_TotalPhysicalRAM': 'float32',
        'Census_ChassisTypeName': 'category',
        'Census_InternalPrimaryDiagonalDisplaySizeInInches': 'float16',
        'Census_InternalPrimaryDisplayResolutionHorizontal': 'float16',
        'Census_InternalPrimaryDisplayResolutionVertical': 'float16',
        'Census_PowerPlatformRoleName': 'category',
        'Census_InternalBatteryType': 'category',
        'Census_InternalBatteryNumberOfCharges': 'float32',
        'Census_OSVersion': 'category',
        'Census_OSArchitecture': 'category',
        'Census_OSBranch': 'category',
        'Census_OSBuildNumber': 'int16',
        'Census_OSBuildRevision': 'int32',
        'Census_OSEdition': 'category',
        'Census_OSSkuName': 'category',
        'Census_OSInstallTypeName': 'category',
        'Census_OSInstallLanguageIdentifier': 'float16',
        'Census_OSUILocaleIdentifier': 'int16',
        'Census_OSWUAutoUpdateOptionsName': 'category',
        'Census_IsPortableOperatingSystem': 'int8',
        'Census_GenuineStateName': 'category',
        'Census_ActivationChannel': 'category',
        'Census_IsFlightingInternal': 'float16',
        'Census_IsFlightsDisabled': 'float16',
        'Census_FlightRing': 'category',
        'Census_ThresholdOptIn': 'float16',
        'Census_FirmwareManufacturerIdentifier': 'float16',
        'Census_FirmwareVersionIdentifier': 'float32',
        'Census_IsSecureBootEnabled': 'int8',
        'Census_IsWIMBootEnabled': 'float16',
        'Census_IsVirtualDevice': 'float16',
        'Census_IsTouchEnabled': 'int8',
        'Census_IsPenCapable': 'int8',
        'Census_IsAlwaysOnAlwaysConnectedCapable': 'float16',
        'Wdft_IsGamer': 'float16',
        'Wdft_RegionIdentifier': 'float16',
        'HasDetections': 'int8'
    }

    train = pd.read_csv('input/train.csv', dtype=dtypes, low_memory=True, nrows=num_row)
    train['MachineIdentifier'] = train.index.astype('uint32')
    test = pd.read_csv('input/test.csv', dtype=dtypes, low_memory=True, nrows=num_row)
    test['MachineIdentifier'] = test.index.astype('uint32')

    gc.collect()

    return train, test


def write_to_pickle(train, test):
    train.to_pickle('input/train.pkl')
    test.to_pickle('input/test.pkl')
    return None


def read_pickle():
    train = pd.read_pickle('input/train.pkl')
    test = pd.read_pickle('input/test.pkl')
    return train, test


def initial_engineering(train, test):
    AppVersion = train.AppVersion.str.split('.', expand=True)
    AppVersion.columns = ['AppVersion'+str(name) for name in AppVersion.columns]
    train = pd.concat([train, AppVersion], axis=1)

    AppVersion = test.AppVersion.str.split('.', expand=True)
    AppVersion.columns = ['AppVersion' + str(name) for name in AppVersion.columns]
    test = pd.concat([test, AppVersion], axis=1)

    del AppVersion, train['AppVersion'], test['AppVersion']

    # TODO consider delete Appversion column

    gc.collect()

    return train, test



def drop_useless(train, test):
    droppable_features = [
         'Census_ProcessorClass',
         'Census_IsWIMBootEnabled',
         'IsBeta',
         'Census_IsFlightsDisabled',
         'Census_IsFlightingInternal',
         'AutoSampleOptIn',
         'Census_ThresholdOptIn',
         'SMode',
         'Census_IsPortableOperatingSystem',
         'PuaMode',
         'Census_DeviceFamily',
         'UacLuaenable',
         'Census_IsVirtualDevice',
         'Platform',
         'Census_OSSkuName',
         'Census_OSInstallLanguageIdentifier',
         'Processor'
    ]
    train.drop(columns=droppable_features, inplace=True)
    test.drop(columns=droppable_features, inplace=True)

    gc.collect()

    return train, test


def transfer_sparse(train, test):

    for usecol in train.columns.tolist():

        if usecol in ['MachineIdentifier', 'HasDetections']:
            continue

        train[usecol] = train[usecol].astype('str')
        test[usecol] = test[usecol].astype('str')

        # Fit LabelEncoder
        le = LabelEncoder().fit(
            np.unique(train[usecol].unique().tolist() +
                      test[usecol].unique().tolist()))

        # At the end 0 will be used for dropped values
        train[usecol] = le.transform(train[usecol]) + 1
        test[usecol] = le.transform(test[usecol]) + 1

        agg_tr = (train
                  .groupby([usecol])
                  .aggregate({'MachineIdentifier': 'count'})
                  .reset_index()
                  .rename({'MachineIdentifier': 'Train'}, axis=1))
        agg_te = (test
                  .groupby([usecol])
                  .aggregate({'MachineIdentifier': 'count'})
                  .reset_index()
                  .rename({'MachineIdentifier': 'Test'}, axis=1))

        agg = pd.merge(agg_tr, agg_te, on=usecol, how='outer').replace(np.nan, 0)
        # Select values with more than 1000 observations
        agg = agg[(agg['Train'] > 1000)].reset_index(drop=True)
        agg['Total'] = agg['Train'] + agg['Test']
        # Drop unbalanced values
        agg = agg[(agg['Train'] / agg['Total'] > 0.2) & (agg['Train'] / agg['Total'] < 0.8)]
        agg[usecol + 'Copy'] = agg[usecol]

        train[usecol] = (pd.merge(train[[usecol]],
                                  agg[[usecol, usecol + 'Copy']],
                                  on=usecol, how='left')[usecol + 'Copy']
                         .replace(np.nan, 0).astype('int').astype('category'))

        test[usecol] = (pd.merge(test[[usecol]],
                                 agg[[usecol, usecol + 'Copy']],
                                 on=usecol, how='left')[usecol + 'Copy']
                        .replace(np.nan, 0).astype('int').astype('category'))

        del le, agg_tr, agg_te, agg, usecol
        gc.collect()

    # y_train = np.array(train['HasDetections'])
    y_train = train['HasDetections']
    train_ids = train.index
    test_ids = test.index

    del train['HasDetections'], train['MachineIdentifier'], test['MachineIdentifier']
    gc.collect()

    return y_train, train_ids, test_ids, train, test


def add_noise(series, noise_level):
    return series * (1 + noise_level * np.random.randn(len(series)))


def target_encode(trn_series=None,
                  tst_series=None,
                  target=None,
                  min_samples_leaf=1,
                  smoothing=1,
                  noise_level=0):
    """
    Smoothing is computed like in the following paper by Daniele Micci-Barreca
    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf
    trn_series : training categorical feature as a pd.Series
    tst_series : test categorical feature as a pd.Series
    target : target data as a pd.Series
    min_samples_leaf (int) : minimum samples to take category average into account
    smoothing (int) : smoothing effect to balance categorical average vs prior
    """
    assert len(trn_series) == len(target)
    assert trn_series.name == tst_series.name
    temp = pd.concat([trn_series, target], axis=1)
    # Compute target mean
    averages = temp.groupby(by=trn_series.name)[target.name].agg(["mean", "count"])
    # Compute smoothing
    smoothing = 1 / (1 + np.exp(-(averages["count"] - min_samples_leaf) / smoothing))
    # Apply average function to all target data
    prior = target.mean()
    # The bigger the count the less full_avg is taken into account
    averages[target.name] = prior * (1 - smoothing) + averages["mean"] * smoothing
    averages.drop(["mean", "count"], axis=1, inplace=True)
    # Apply averages to trn and tst series
    ft_trn_series = pd.merge(
        trn_series.to_frame(trn_series.name),
        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),
        on=trn_series.name,
        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)
    # pd.merge does not keep the index so restore it
    ft_trn_series.index = trn_series.index
    ft_tst_series = pd.merge(
        tst_series.to_frame(tst_series.name),
        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),
        on=tst_series.name,
        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)
    # pd.merge does not keep the index so restore it
    ft_tst_series.index = tst_series.index
    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)


def one_hot(train, test):
    ohe = OneHotEncoder(sparse=True, dtype='uint8', categories='auto').fit(train)

    # Transform data using small groups to reduce memory usage
    m = 10 ** 5
    train = vstack([ohe.transform(train[i * m:(i + 1) * m]) for i in range(train.shape[0] // m + 1)])
    test = vstack([ohe.transform(test[i * m:(i + 1) * m]) for i in range(test.shape[0] // m + 1)])

    del ohe
    gc.collect()

    return train, test, m


def k_fold_lgbm(train, test, y_train, train_ids, test_ids, m, debug):

    y_train = np.array(y_train)
    num_fold = 2 if debug else 5
    skf = StratifiedKFold(n_splits=num_fold, shuffle=True, random_state=777)
    skf.get_n_splits(train_ids, y_train)

    lgb_test_result = np.zeros(test_ids.shape[0])
    # lgb_train_result = np.zeros(train_ids.shape[0])
    # xgb_test_result  = np.zeros(test_ids.shape[0])
    # xgb_train_result = np.zeros(train_ids.shape[0])
    counter = 0

    print('\nLightGBM\n')

    for train_index, test_index in skf.split(train_ids, y_train):
        print('Fold {}\n'.format(counter + 1))

        feature_importances = np.zeros(train.shape[1])

        # train = load_npz('train.npz')
        X_fit = vstack([train[train_index[i * m:(i + 1) * m]] for i in range(train_index.shape[0] // m + 1)])
        X_val = vstack([train[test_index[i * m:(i + 1) * m]] for i in range(test_index.shape[0] // m + 1)])
        X_fit, X_val = csr_matrix(X_fit, dtype='float32'), csr_matrix(X_val, dtype='float32')
        y_fit, y_val = y_train[train_index], y_train[test_index]
        scores = []

        # del train
        # gc.collect()

        # TODO use learning of 0.02 if time permits
        lgb_model = lgb.LGBMClassifier(max_depth=0,
                                       n_estimators=30000,
                                       learning_rate=0.05,
                                       num_leaves=2 ** 12 - 1,
                                       colsample_bytree=0.28,
                                       objective='binary',
                                       n_jobs=-1,
                                       reg_alpha=10,
                                       # reg_lambda=0.1,
                                       # subsample_freq=1
                                       )

        # xgb_model = xgb.XGBClassifier(max_depth=6,
        #                              n_estimators=30000,
        #                              colsample_bytree=0.2,
        #                              learning_rate=0.1,
        #                              objective='binary:logistic',
        #                              n_jobs=-1)

        lgb_model.fit(X_fit, y_fit, eval_metric='auc',
                      eval_set=[(X_val, y_val)],
                      verbose=100, early_stopping_rounds=100)

        # xgb_model.fit(X_fit, y_fit, eval_metric='auc',
        #              eval_set=[(X_val, y_val)],
        #              verbose=1000, early_stopping_rounds=300)

        # lgb_train_result[test_index] += lgb_model.predict_proba(X_val)[:,1]
        # xgb_train_result[test_index] += xgb_model.predict_proba(X_val)[:,1]

        scores.append(lgb_model.best_score_['valid_0']['auc'])

        del X_fit, X_val, y_fit, y_val, train_index, test_index
        gc.collect()

        # test = load_npz('test.npz')
        test = csr_matrix(test, dtype='float32')
        lgb_test_result += lgb_model.predict_proba(test)[:, 1]
        feature_importances += lgb_model.feature_importances_

        # xgb_test_result += xgb_model.predict_proba(test)[:,1]
        counter += 1

    score = np.mean(scores)

    feature_importances = feature_importances/counter
    zero_features = np.argwhere(feature_importances == 0).tolist()
    zero_features = [i[0] for i in zero_features]

    print('\nThere are %d features with 0.0 importance' % len(zero_features))
    print(zero_features)

    # del test
    # gc.collect()

    return lgb_test_result/counter, round(score, 3), zero_features


def save_submission(lgb_test_result, score):
    submission = pd.read_csv('input/sample_submission.csv')
    submission['HasDetections'] = lgb_test_result
    submission.to_csv('output/lgb_submission_' + str(score) + '.csv', index=False)
    return None
